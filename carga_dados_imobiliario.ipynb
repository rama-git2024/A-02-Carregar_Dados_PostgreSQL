{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c36915-d9b5-488c-baa1-c92e2f4a4dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPY 12\n",
      "\n",
      "Novos dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import docker\n",
    "import tarfile\n",
    "from io import BytesIO\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurações do banco de dados\n",
    "db_config = {\n",
    "    'dbname': 'rama',\n",
    "    'user': 'pcecere',\n",
    "    'password': '244049',\n",
    "    'host': 'localhost',\n",
    "    'port': 5434\n",
    "}\n",
    "\n",
    "# Caminho para o arquivo Excel e CSV\n",
    "excel_file_path = r'X:\\Recuperação\\Crédito Imobiliário\\Acompanhamento\\Distribuições ONR – 2024 v1.xlsx'\n",
    "sheet_name = 'Dados'  # Altere para o nome da aba correta\n",
    "container_id = '223c59c1268f'  # Substitua pelo ID do seu container\n",
    "\n",
    "def read_and_process_excel(excel_file_path, sheet_name):\n",
    "    df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "\n",
    "    rename_df = {\n",
    "        'Data AF 0.7': 'af_07',\n",
    "        'Data AF 1.1': 'af_11',\n",
    "        'Data Distribuição': 'data_distribuicao',\n",
    "        'Código': 'codigo',\n",
    "        'Dossiê': 'dossie',\n",
    "        'Nome do Mutuário': 'adverso',\n",
    "        'Produto': 'produto',\n",
    "        'Responsável': 'responsavel',\n",
    "        'Mês Distr.': 'mes_distribuicao',\n",
    "        'Temp. Distr.': 'tempo_distribuicao'\n",
    "    }\n",
    "    df.rename(columns=rename_df, inplace=True)\n",
    "\n",
    "    df = df.dropna(subset=['tempo_distribuicao'])\n",
    "\n",
    "    date_columns = ['af_07', 'af_11', 'data_distribuicao']\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col]).dt.date\n",
    "\n",
    "    df['tempo_distribuicao'] = df['tempo_distribuicao'].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_existing_records(db_config):\n",
    "    engine = create_engine(f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\")\n",
    "    query = \"SELECT dossie FROM imobiliario.distribuicao\"\n",
    "    existing_records = pd.read_sql(query, engine)\n",
    "    return existing_records\n",
    "\n",
    "def save_df_to_csv(df, csv_file_path):\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "def copy_csv_to_docker_container(csv_file_path, container_id):\n",
    "    client = docker.from_env()\n",
    "    container = client.containers.get(container_id)\n",
    "\n",
    "    with BytesIO() as tar_stream:\n",
    "        with tarfile.open(fileobj=tar_stream, mode='w') as tar:\n",
    "            tar.add(csv_file_path, arcname='dados.csv')\n",
    "        tar_stream.seek(0)\n",
    "        container.put_archive('/tmp', tar_stream)\n",
    "\n",
    "def execute_command_in_container(container_id, command):\n",
    "    client = docker.from_env()\n",
    "    container = client.containers.get(container_id)\n",
    "    exec_id = container.exec_run(command)\n",
    "    print(exec_id.output.decode())\n",
    "\n",
    "def insert_new_data(df_new_data, db_config, container_id, csv_file_name):\n",
    "    # Salva o novo dataframe como CSV\n",
    "    df_new_data.to_csv(csv_file_name, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Copia o CSV para o container Docker\n",
    "    copy_csv_to_docker_container(csv_file_name, container_id)\n",
    "\n",
    "    # Carrega os novos dados\n",
    "    load_csv_command = f\"psql -U {db_config['user']} -d {db_config['dbname']} -c \\\"COPY imobiliario.distribuicao FROM '/tmp/{csv_file_name}' DELIMITER ',' CSV HEADER\\\"\"\n",
    "    execute_command_in_container(container_id, load_csv_command)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ler e processar o Excel\n",
    "    df = read_and_process_excel(excel_file_path, sheet_name)\n",
    "\n",
    "    # Obter os registros existentes no banco de dados\n",
    "    existing_records = get_existing_records(db_config)\n",
    "\n",
    "    # Comparar os dados novos com os existentes para identificar novos dossiês\n",
    "    df_new_data = df[~df['dossie'].isin(existing_records['dossie'])]\n",
    "\n",
    "    if not df_new_data.empty:\n",
    "        # Se houver novos dados, insira-os no banco\n",
    "        insert_new_data(df_new_data, db_config, container_id, 'dados.csv')\n",
    "        os.remove('dados.csv')\n",
    "        print(\"Novos dados carregados com sucesso!\")\n",
    "    else:\n",
    "        print(\"Nenhum novo dado para carregar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0f3349-510e-44b0-b14f-1dca7f115cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPY 3\n",
      "\n",
      "Novos dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import docker\n",
    "import tarfile\n",
    "from io import BytesIO\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurações do banco de dados\n",
    "db_config = {\n",
    "    'dbname': 'rama',\n",
    "    'user': 'pcecere',\n",
    "    'password': '244049',\n",
    "    'host': 'localhost',\n",
    "    'port': 5434\n",
    "}\n",
    "\n",
    "# Caminho para o arquivo Excel e CSV\n",
    "excel_file_path = r'X:\\Recuperação\\Crédito Imobiliário\\Acompanhamento\\Controle de Intimações Positivas 2024.xlsx'\n",
    "csv_file_path = r'C:\\Users\\pedro.cecere\\Desktop\\dados2.csv'\n",
    "sheet_name = 'Dados'  # Altere para o nome da aba correta\n",
    "container_id = '223c59c1268f'  # Substitua pelo ID do seu container\n",
    "\n",
    "def read_and_process_excel(excel_file_path, sheet_name):\n",
    "    # Ler a planilha do Excel\n",
    "    df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Alterar o nome das colunas do df\n",
    "    rename_df = {\n",
    "        'Dt. Distr. (AF 1.1)': 'af_11',\n",
    "        'Dt. Intim. Todos (AF 2.8)': 'af_28',\n",
    "        'Dt. Ciência Intim.': 'todos_citados',\n",
    "        'TM Intim. (dias)': 'tm_intimacao',\n",
    "        'Tipo Intim.': 'tipo_intimacao',\n",
    "        'Produto': 'produto',\n",
    "        'Dossiê nº': 'dossie',\n",
    "        'Adverso': 'adverso',\n",
    "        'Comarca': 'comarca',\n",
    "        'UF': 'uf',\n",
    "        'Últ. Evento WF': 'ultimo_evento_wf',\n",
    "        'Responsável Intimação': 'resp_intmacao',\n",
    "        'Responsável Consolidação': 'resp_consolidacao',\n",
    "        'Mês': 'mes'\n",
    "    }\n",
    "    df.rename(columns=rename_df, inplace=True)\n",
    "\n",
    "    # Alterar tipo de dado das colunas para tipo date\n",
    "    date_columns = ['af_11', 'af_28', 'todos_citados']\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col]).dt.date\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_existing_records(db_config):\n",
    "    # Obter os registros existentes no banco de dados\n",
    "    engine = create_engine(f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\")\n",
    "    query = \"SELECT dossie FROM imobiliario.int_positiva\"\n",
    "    existing_records = pd.read_sql(query, engine)\n",
    "    return existing_records\n",
    "\n",
    "def save_df_to_csv(df, csv_file_path):\n",
    "    # Salvar o DataFrame em um arquivo CSV com encoding UTF-8-SIG\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "def copy_csv_to_docker_container(csv_file_path, container_id):\n",
    "    # Copiar o arquivo CSV para o container Docker\n",
    "    client = docker.from_env()\n",
    "    container = client.containers.get(container_id)\n",
    "\n",
    "    # Criar um arquivo tar do CSV\n",
    "    with BytesIO() as tar_stream:\n",
    "        with tarfile.open(fileobj=tar_stream, mode='w') as tar:\n",
    "            tar.add(csv_file_path, arcname='dados2.csv')\n",
    "        tar_stream.seek(0)\n",
    "        container.put_archive('/tmp', tar_stream)\n",
    "\n",
    "def execute_command_in_container(container_id, command):\n",
    "    client = docker.from_env()\n",
    "    container = client.containers.get(container_id)\n",
    "    exec_id = container.exec_run(command)\n",
    "    print(exec_id.output.decode())\n",
    "\n",
    "def insert_new_data(df_new_data, db_config, container_id, csv_file_name):\n",
    "    # Define o caminho completo para o arquivo CSV\n",
    "    csv_file_path = r'C:\\Users\\pedro.cecere\\Desktop' + '\\\\' + csv_file_name\n",
    "    \n",
    "    # Salva o novo dataframe como CSV no caminho especificado\n",
    "    df_new_data.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Copia o CSV para o container Docker\n",
    "    copy_csv_to_docker_container(csv_file_path, container_id)\n",
    "\n",
    "    # Carrega os novos dados\n",
    "    load_csv_command = f\"psql -U {db_config['user']} -d {db_config['dbname']} -c \\\"COPY imobiliario.int_positiva FROM '/tmp/{csv_file_name}' DELIMITER ',' CSV HEADER\\\"\"\n",
    "    execute_command_in_container(container_id, load_csv_command)\n",
    "\n",
    "    return csv_file_path\n",
    "if __name__ == \"__main__\":\n",
    "    # Ler e processar o Excel\n",
    "    df = read_and_process_excel(excel_file_path, sheet_name)\n",
    "\n",
    "    # Obter os registros existentes no banco de dados\n",
    "    existing_records = get_existing_records(db_config)\n",
    "\n",
    "    # Comparar os dados novos com os existentes para identificar novos dossiês\n",
    "    df_new_data = df[~df['dossie'].isin(existing_records['dossie'])]\n",
    "\n",
    "    if not df_new_data.empty:\n",
    "        # Se houver novos dados, insira-os no banco e obtenha o caminho do arquivo CSV\n",
    "        csv_file_path = insert_new_data(df_new_data, db_config, container_id, 'dados2.csv')\n",
    "        \n",
    "        # Remover o arquivo CSV após o uso\n",
    "        os.remove(csv_file_path)\n",
    "        print(\"Novos dados carregados com sucesso!\")\n",
    "    else:\n",
    "        print(\"Nenhum novo dado para carregar.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
